[models]
llm = Ollama
using_model = gpt-3.5-turbo
simulation_model = gpt-3.5-turbo
model_1 = gpt-3.5-turbo
model_2 = ollama_openhermes

[path]
output_path = ./output